{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-traitement des résultats du k-mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook va permettre d'évaluer l'efficacité de plusieurs versions de l'algorithme de post-traitement, en particulier le calcul du mode statistique, pour l'estimation du triplet `(r, g, b)` le plus fréquent dans un voisinage de points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geo3dfeatures import features, extract, postprocess\n",
    "from geo3dfeatures.tools import kmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = Path(\"..\", \"data\")\n",
    "experiment = \"b9\"\n",
    "xyz = True\n",
    "n_neighbors = 50\n",
    "radius = None\n",
    "n_clusters = 3\n",
    "binsize = 1.0\n",
    "feature_set = \"full\"\n",
    "config_name = \"base\"\n",
    "config_path = Path(\"..\", \"config\", config_name + \".ini\")\n",
    "kd_tree_leaf_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10_000\n",
    "SEED = 1337"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul des clusters via le k-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:10:50] kmean.load_features (INFO) - Recover features stored in ../data/output/b9/features/features-n50-full-binsize-1.0.csv\n"
     ]
    }
   ],
   "source": [
    "data = kmean.load_features(datapath, experiment, n_neighbors, radius, feature_set, binsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22300, 25)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_config = kmean.read_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = data[[\"x\", \"y\", \"z\"]].copy()\n",
    "data.drop(columns=[\"x\", \"y\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in data.columns:\n",
    "    data[c] = features.max_normalize(data[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"bin_z_range\" in data.columns:\n",
    "    data[\"bin_z_range\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean.update_features(data, feature_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MiniBatchKMeans(n_clusters=n_clusters, batch_size=BATCH_SIZE, random_state=SEED)\n",
    "model.fit(data)\n",
    "labels = model.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du kd-tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_file = Path(datapath, \"output\", experiment, \"kd-tree-leaf-\" + str(kd_tree_leaf_size) + \".pkl\")\n",
    "with open(tree_file, \"rb\") as fobj:\n",
    "    tree = pickle.load(fobj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition des méthodes de calcul du mode statistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche ici à trouver le triplet `(r, g, b)` le plus fréquent dans le voisinage de chacun des 22300 points du nuage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "colored_results = kmean.colorize_clusters(points, labels)\n",
    "colored_values = colored_results.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthode 1: `scipy.stats.mode()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette méthode, on itère sur toutes les lignes du dataframe (avec `df.values`, plus efficace que `df.iterrows()`), et pour chaque point examiné, on fait une requête au kd-tree pour avoir l'ensemble de ses voisins, puis on calcule le mode statistique avec `scipy.stats.mode`, qui renvoie la valeur la plus fréquente dans un tableau à une dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode1(df, tree, n_neighbors):\n",
    "    new_clusters = []\n",
    "    for point in df.values[:int(df.shape[0] * 0.1)]:  # On ne considère que 10% du nuage de point\n",
    "        _, neighbors = extract.request_tree(point[:3], tree, n_neighbors, None)\n",
    "        new_cluster = scipy.stats.mode(df.values[neighbors, 3:]).mode\n",
    "        new_clusters.append(new_cluster)\n",
    "    return new_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.68 s ± 105 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit mode1(colored_results, tree, n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthode 2: `groupby().count()` de pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, même structure que précédemment, sauf qu'on utilise une construction purement issue de `pandas`, avec un `groupby`, un décompte sur chacun des groupes, et la sélection du groupe majoritaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode2(df, tree, n_neighbors):\n",
    "    new_clusters = []\n",
    "    for point in df.values[:int(df.shape[0] * 0.1)]:  # On ne considère que 10% du nuage de point\n",
    "        _, neighbors = extract.request_tree(point[:3], tree, n_neighbors, None)\n",
    "        new_cluster = df.iloc[neighbors].groupby([\"r\", \"g\", \"b\"])[\"x\"].count().idxmax()\n",
    "        new_clusters.append(new_cluster)\n",
    "    return new_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.32 s ± 376 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit mode2(colored_results, tree, n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthode 3: `mode()` de pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette troisième méthode, il s'agit toujours d'itérer sur les lignes du dataframe, en appliquant cette fois-ci la méthode `mode()` propre à pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode3(df, tree, n_neighbors):\n",
    "    new_clusters = []\n",
    "    for point in df.values[:int(df.shape[0] * 0.1)]:  # On ne considère que 10% du nuage de point\n",
    "        _, neighbors = extract.request_tree(point[:3], tree, n_neighbors, None)\n",
    "        new_cluster = df.iloc[neighbors, 3:].mode()\n",
    "        new_clusters.append(new_cluster)\n",
    "    return new_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.33 s ± 577 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit mode3(colored_results, tree, n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthode 4: adaptation de `scipy.stats.mode()` pour un `np.array` multidimensionnel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette quatrième méthode, on change de paradigme, et on s'intéresse de plus près à la façon de produire un mode statistique \"à la main\", sur l'intégralité du jeu de données, en exploitant `numpy`. Cela nous conduit à calculer les voisins en une fois, en amont du process (on profite là de la souplesse de `scipy` pour la manipulation du kd-tree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode4(data, tree, n_neighbors):\n",
    "    \"\"\"See https://github.com/scipy/scipy/blob/master/scipy/stats/stats.py#L458\n",
    "    \"\"\"\n",
    "    _, neighbors = extract.request_tree(data[:,:3], tree, n_neighbors, radius)\n",
    "    arr = data[neighbors, 3:]\n",
    "    scores = np.unique(np.reshape(arr, (-1, arr.shape[-1])), axis=0)\n",
    "    mostfrequent = np.squeeze(np.zeros((arr.shape[0], arr.shape[2])))\n",
    "    oldcounts = np.zeros(arr.shape[0])\n",
    "    for score in scores:\n",
    "        template = np.all(arr == score, axis=2)\n",
    "        counts = np.sum(template, axis=1)\n",
    "        mostfrequent[counts > oldcounts] = score\n",
    "        oldcounts = np.maximum(counts, oldcounts)\n",
    "    return mostfrequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.61 s ± 169 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit mode4(colored_values, tree, n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthode 5: adaptation de `np.argmax(np.bincount())` pour un `np.array` multidimensionnel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idem que précédemment, sauf qu'on généralise tout ça en appliquant la même logique que dans la méthode 2, à savoir `np.bincount` associé à `np.argmax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode5(data, tree, n_neighbors):\n",
    "    \"\"\"See https://stackoverflow.com/questions/12297016/how-to-find-most-frequent-values-in-numpy-ndarray\n",
    "    \"\"\"\n",
    "    _, neighbors = extract.request_tree(data[:,:3], tree, n_neighbors, radius)\n",
    "    arr = data[neighbors, 3:]\n",
    "    u, indices = np.unique(arr, return_inverse=True)\n",
    "    return u[np.argmax(np.apply_along_axis(np.bincount, 1, indices.reshape(arr.shape), None, np.max(indices)+1), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.05 s ± 37 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit mode5(colored_values, tree, n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bilan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En résumé, on note des performances bien supérieures si on traite tout le dataset d'un seul coup, en employant les capacités de `numpy` !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| méthode |       temps       |        commentaire            |\n",
    "|---------|-------------------|-------------------------------|\n",
    "| 1       | 1.68s+/-0.105s    | 10% des 22300 points étudiés  |\n",
    "| 2       | 5.32s+/-0.376s    | 10% des 22300 points étudiés  |\n",
    "| 3       | 7.33s+/-0.577s    | 10% des 22300 points étudiés  |\n",
    "| 4       | 2.61s+/-0.169s    |                               |\n",
    "| 5       | 1.05s+/-0.037s    |                               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etre plus malin, et calculer le mode sur les labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jusqu'à présent, les modes statistiques ont été calculés sur trois colonnes, à savoir les 3 canaux RGB. Avant de faire cette transformation, les étiquettes associées au clustering représentent une seule colonne. Calculer des modes sous cette forme doit pouvoir être plus rapide, et moins consommateur en RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_point_cloud = np.append(point_cloud, np.expand_dims(labels, axis=1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438 ms ± 8.92 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit mode5(labelled_point_cloud, tree, n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit qu'on réduit ainsi encore le temps de calcul de près de deux tiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
