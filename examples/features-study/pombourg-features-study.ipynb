{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature study - Pombourg scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook details the geometric features for the `Pombourg` dataset. In order to illustrate the study, the screencast below represents the point cloud as seen with `CloudCompare`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../docs/images/pombourg.png\" width=\"300px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geo3dfeatures.io import las as read_las\n",
    "from geo3dfeatures.extract import process_full\n",
    "from geo3dfeatures.extract import compute_tree, request_tree, extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX_NAME = \"Pombourg\"\n",
    "SCENE_FILE = PREFIX_NAME + \".las\"\n",
    "EBOULIS_FILE = PREFIX_NAME + \"_eboulis.las\"\n",
    "VEGETATION_FILE = PREFIX_NAME + \"_vegetation.las\"\n",
    "FALAISE_FILE = PREFIX_NAME + \"_falaise.las\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAFOLDER = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = Path(\"../..\", DATAFOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = {\"eboulis\": 0,\n",
    "          \"falaise\": 1,\n",
    "          \"vegetation\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates labels\n",
    "COORDS = list(\"xyz\")\n",
    "# RGB color labels\n",
    "COULEURS = list(\"rgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = read_las(DATADIR / \"input\" / SCENE_FILE)\n",
    "rawdata = pd.DataFrame(rawdata, columns=list(\"xyzrgb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dimension: \", rawdata.shape)\n",
    "rawdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEAF_SIZE = 1_000\n",
    "N_NEIGHBORS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = compute_tree(rawdata[COORDS].values, leaf_size=LEAF_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We request the KD-tree so as to retrieve the neighbors (k=10) of a given point, and the corresponding distances to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_point = rawdata[COORDS].sample()\n",
    "distance, neighbors_index = request_tree(random_point.values, tree, N_NEIGHBORS)\n",
    "distance, neighbors_index = distance.squeeze(), neighbors_index.squeeze()\n",
    "print(\"distance: \", distance)\n",
    "print(\"index: \", neighbors_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence the following table contains the requested point (first row) and its 10 closest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata.loc[neighbors_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute some basic statistics about distance with neighbors (expressed in meters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(distance).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class sample features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim at computing all the features on every `Pombourg` sample, with respect to the entire scene. The subsequent geometric features can be computed considering a set of different neighborhood sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegetation = pd.DataFrame(read_las(DATADIR / \"input\" / VEGETATION_FILE), columns=COORDS + COULEURS)\n",
    "falaise = pd.DataFrame(read_las(DATADIR / \"input\" / FALAISE_FILE), columns=COORDS + COULEURS)\n",
    "eboulis = pd.DataFrame(read_las(DATADIR / \"input\" / EBOULIS_FILE), columns=COORDS + COULEURS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimension of `vegetation` dataset: \", vegetation.shape)\n",
    "print(\"dimension of `falaise` dataset: \", falaise.shape)\n",
    "print(\"dimension of `eboulis` dataset: \", eboulis.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance assessment with respect to neighborhood size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the following neighborhood range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOISINS_NUM = [10, 20, 30, 50, 100, 200, 500, 1000, 1500, 2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have an insight about the neighboring sphere dimension by computing the mean distance (in meter) for each neighborhood size, *e.g.* by considering 20-point samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vegetation neighborhood sizes:\")\n",
    "veg_sample = vegetation[COORDS].sample(20).values\n",
    "gen = (request_tree(veg_sample, tree, num) for num in VOISINS_NUM)\n",
    "d = [{\"mean (in meter)\": d.mean(axis=1)[0], \"max (in meter)\": d.max(axis=1)[0]} for d, _ in gen]\n",
    "pd.DataFrame(d, index=VOISINS_NUM).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cliff neighborhood sizes:\")\n",
    "falaise_sample = falaise[COORDS].sample(20).values\n",
    "gen = (request_tree(falaise_sample, tree, num) for num in VOISINS_NUM)\n",
    "d = [{\"mean (in meter)\": d.mean(axis=1)[0], \"max (in meter)\": d.max(axis=1)[0]} for d, _ in gen]\n",
    "pd.DataFrame(d, index=VOISINS_NUM).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 1000 neighbors, the neighboring sphere is close to 1 meter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare some feature profile with respect to neighboring sphere size (resp. neighbor quantity), for each class (`falaise`, `eboulis`, `vegetation`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_PATH = Path(\"../..\", DATAFOLDER, \"output\", PREFIX_NAME, \"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer** The next cell must be run *after* running the featurization step for each scene sample.\n",
    "\n",
    "Consider the following command, for each class:\n",
    "\n",
    "```\n",
    "geo3d featurize -d <datafolder> -i Pombourg_<class>.las -c r g b -t 500 -n 10 20 30 50 100 200 500 1000 1500 2000 --label-scene\n",
    "```\n",
    "\n",
    "where `datafolder` is the name of the data folder at the project root, on your file system, and `class` is the requested class (`vegetation`, `eboulis`, `falaise`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegetation_store = pd.HDFStore(FEATURE_PATH / \"features_vegetation.h5\", \"r\")\n",
    "falaise_store = pd.HDFStore(FEATURE_PATH / \"features_falaise.h5\", \"r\")\n",
    "eboulis_store = pd.HDFStore(FEATURE_PATH / \"features_eboulis.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYS = {i: \"/num_{:04d}\".format(i) for i in VOISINS_NUM}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_features(store, feature_name):\n",
    "    result = pd.Series({num: store[\"/num_{:04d}\".format(num)][feature_name].mean() for num in VOISINS_NUM})\n",
    "    result.name = feature_name\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance : radius & radius 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = pd.DataFrame({\"vegetation\": mean_features(vegetation_store, \"radius\"),\n",
    "                       \"falaise\": mean_features(falaise_store, \"radius\"),\n",
    "                       \"eboulis\": mean_features(eboulis_store, \"radius\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius.plot(kind=\"bar\", title=\"radius\")\n",
    "plt.xlabel(\"Neighborhood size\")\n",
    "plt.ylabel(\"Mean radius (m)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius_2d = pd.DataFrame({\"vegetation\": mean_features(vegetation_store, \"radius_2D\"),\n",
    "                         \"falaise\": mean_features(falaise_store, \"radius_2D\"),\n",
    "                         \"eboulis\": mean_features(eboulis_store, \"radius_2D\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius_2d.plot(kind=\"bar\", title=\"Radius 2D (x, y)\")\n",
    "plt.xlabel(\"Neighborhood size\")\n",
    "plt.ylabel(\"Mean 2D radius (m)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Densité - 2D et 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"density_2D\"\n",
    "density_2d = pd.DataFrame({\"vegetation\": mean_features(vegetation_store, key),\n",
    "                           \"falaise\": mean_features(falaise_store, key),\n",
    "                           \"eboulis\": mean_features(eboulis_store, key)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_2d.plot(kind=\"bar\", title=\"Density 2D\")\n",
    "plt.xlabel(\"Neighborhood size\")\n",
    "plt.ylabel(\"Mean 2D density (m)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"density\"\n",
    "density_3d = pd.DataFrame({\"vegetation\": mean_features(vegetation_store, key),\n",
    "                           \"falaise\": mean_features(falaise_store, key),\n",
    "                           \"eboulis\": mean_features(eboulis_store, key)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_3d.plot(kind=\"bar\", title=\"Density 3D\")\n",
    "plt.xlabel(\"Neighborhood size\")\n",
    "plt.ylabel(\"Mean density (m)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autres features 2D : eigen sum & ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"eigenvalue_ratio_2D\"\n",
    "eigenratio_2d = pd.DataFrame({\"vegetation\": mean_features(vegetation_store, key),\n",
    "                           \"falaise\": mean_features(falaise_store, key),\n",
    "                           \"eboulis\": mean_features(eboulis_store, key)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenratio_2d.plot(kind=\"bar\", title=\"Eigen ratio 2D\")\n",
    "plt.xlabel(\"Neighborhood size\")\n",
    "plt.ylabel(\"Mean e2 / e1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"eigenvalue_sum_2D\"\n",
    "eigensum_2d = pd.DataFrame({\"vegetation\": mean_features(vegetation_store, key),\n",
    "                           \"falaise\": mean_features(falaise_store, key),\n",
    "                           \"eboulis\": mean_features(eboulis_store, key)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigensum_2d.plot(kind=\"bar\", title=\"Eigen sum 2D\")\n",
    "plt.xlabel(\"Neighborhood size\")\n",
    "plt.ylabel(\"Mean eigenvalue sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### alpha & beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = pd.DataFrame({\"vegetation\": mean_features(vegetation_store, \"alpha\"),\n",
    "                     \"falaise\": mean_features(falaise_store, \"alpha\"),\n",
    "                     \"eboulis\": mean_features(eboulis_store, \"alpha\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bigger the `alpha`, the more 1D the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha.plot(kind='bar', title=\"alpha\")\n",
    "plt.xlabel(\"Neighborhood size\")\n",
    "plt.ylabel(\"alpha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = pd.DataFrame({\"vegetation\": mean_features(vegetation_store, \"beta\"),\n",
    "                     \"falaise\": mean_features(falaise_store, \"beta\"),\n",
    "                     \"eboulis\": mean_features(eboulis_store, \"beta\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bigger `beta` is, the more 2D the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta.plot(kind=\"bar\", title=\"beta\")\n",
    "plt.xlabel(\"Neighborhood size\")\n",
    "plt.ylabel(\"beta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the bigger `1 - (alpha + beta)` is, the more 3D the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 - (alpha + beta)).plot(kind=\"bar\", title='1 - (alpha + beta)')\n",
    "plt.xlabel(\"Neighborhood size\")\n",
    "plt.ylabel(\"1 - (alpha + beta)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to plot the evolution of these features for each class, with respect to neighborhood size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_vegetation = pd.DataFrame({\"alpha\": mean_features(vegetation_store, \"alpha\"),\n",
    "                     \"beta\": mean_features(vegetation_store, \"beta\")})\n",
    "\n",
    "triangle_vegetation[\"gamma\"] = triangle_vegetation.eval(\"1 - alpha - beta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_vegetation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_vegetation.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_falaise = pd.DataFrame({\"alpha\": mean_features(falaise_store, \"alpha\"),\n",
    "                     \"beta\": mean_features(falaise_store, \"beta\")})\n",
    "\n",
    "triangle_falaise[\"gamma\"] = triangle_falaise.eval(\"1 - alpha - beta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_falaise.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_eboulis = pd.DataFrame({\"alpha\": mean_features(eboulis_store, \"alpha\"),\n",
    "                     \"beta\": mean_features(eboulis_store, \"beta\")})\n",
    "\n",
    "triangle_eboulis[\"gamma\"] = triangle_eboulis.eval(\"1 - alpha - beta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_eboulis.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verticality coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"verticality\"\n",
    "verticality = pd.DataFrame({\"vegetation\": mean_features(vegetation_store, key),\n",
    "                           \"falaise\": mean_features(falaise_store, key),\n",
    "                           \"eboulis\": mean_features(eboulis_store, key)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verticality.plot(kind=\"bar\", title=\"Verticality\")\n",
    "plt.xlabel(\"Neighborhood size\")\n",
    "plt.ylabel(\"Verticality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linerarity, planarity & scattering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"linearity\"\n",
    "linearity = pd.DataFrame({\"vegetation\": mean_features(vegetation_store, key),\n",
    "                          \"falaise\": mean_features(falaise_store, key),\n",
    "                          \"eboulis\": mean_features(eboulis_store, key)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearity.plot(kind=\"bar\", title=\"linearity\")\n",
    "plt.xlabel(\"Neighborhood size\")\n",
    "plt.ylabel(\"Mean (e1-e2)/e1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"planarity\"\n",
    "planarity = pd.DataFrame({\"vegetation\": mean_features(vegetation_store, key),\n",
    "                          \"falaise\": mean_features(falaise_store, key),\n",
    "                          \"eboulis\": mean_features(eboulis_store, key)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planarity.plot(kind=\"bar\", title=\"planarity\")\n",
    "plt.xlabel(\"Neighborhood size\")\n",
    "plt.ylabel(\"Mean (e2 - e3)/e1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"scattering\"\n",
    "scattering = pd.DataFrame({\"vegetation\": mean_features(vegetation_store, key),\n",
    "                          \"falaise\": mean_features(falaise_store, key),\n",
    "                          \"eboulis\": mean_features(eboulis_store, key)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scattering.plot(kind=\"bar\", title=\"scattering\")\n",
    "plt.xlabel(\"Neighborhood size\")\n",
    "plt.ylabel(\"Mean e3 / e1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Curvature Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"curvature_change\"\n",
    "curvature = pd.DataFrame({\"vegetation\": mean_features(vegetation_store, key),\n",
    "                          \"falaise\": mean_features(falaise_store, key),\n",
    "                          \"eboulis\": mean_features(eboulis_store, key)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curvature.plot(kind=\"bar\", title=\"Curvature change\")\n",
    "plt.xlabel(\"Neighborhood size\")\n",
    "plt.ylabel(\"Mean e3 / (sum e_i)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Omnivariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"omnivariance\"\n",
    "omnivariance = pd.DataFrame({\"vegetation\": mean_features(vegetation_store, key),\n",
    "                          \"falaise\": mean_features(falaise_store, key),\n",
    "                          \"eboulis\": mean_features(eboulis_store, key)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omnivariance.plot(kind=\"bar\", title=\"omnivariance\")\n",
    "plt.xlabel(\"Neighborhood size\")\n",
    "plt.ylabel(\"Mean sqrt(e1*e2*e3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anisotropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"anisotropy\"\n",
    "anisotropy = pd.DataFrame({\"vegetation\": mean_features(vegetation_store, key),\n",
    "                          \"falaise\": mean_features(falaise_store, key),\n",
    "                          \"eboulis\": mean_features(eboulis_store, key)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anisotropy.plot(kind=\"bar\", title=\"anisotopry\")\n",
    "plt.xlabel(\"Neighborhood size\")\n",
    "plt.ylabel(\"Mean (e1 - e3)/e1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eigentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"eigenentropy\"\n",
    "eigentropy = pd.DataFrame({\"vegetation\": mean_features(vegetation_store, key),\n",
    "                          \"falaise\": mean_features(falaise_store, key),\n",
    "                          \"eboulis\": mean_features(eboulis_store, key)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigentropy.plot(kind=\"bar\", title=\"eigen entropy\")\n",
    "plt.xlabel(\"Neighborhood size\")\n",
    "plt.ylabel(\"Mean -sum(e_i * ln e_i)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eigenvalues Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"eigenvalue_sum\"\n",
    "eigensum = pd.DataFrame({\"vegetation\": mean_features(vegetation_store, key),\n",
    "                          \"falaise\": mean_features(falaise_store, key),\n",
    "                          \"eboulis\": mean_features(eboulis_store, key)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigensum.plot(kind=\"bar\", title=\"eigenvalues sum\")\n",
    "plt.xlabel(\"Neighborhood size\")\n",
    "plt.ylabel(\"Mean sum(lambda_i)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After concatenating the dataframes of different neighborhood sizes, we can compute a correlation matrix to have an insight of mathematical relations between our variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOISIN_30 = \"/num_0030\"    # rayon sphère environ 20cm\n",
    "VOISIN_1000 = \"/num_1000\"  # rayon sphère environ 1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_NAMES =  ['alpha',\n",
    " 'beta',\n",
    " 'radius',\n",
    " 'z_range',\n",
    " 'std_dev',\n",
    " 'density',\n",
    " 'verticality',\n",
    " 'curvature_change',\n",
    " 'linearity',\n",
    " 'planarity',\n",
    " 'scattering',\n",
    " 'omnivariance',\n",
    " 'anisotropy',\n",
    " 'eigenentropy',\n",
    " 'eigenvalue_sum',\n",
    " 'radius_2D',\n",
    " 'density_2D',\n",
    " 'eigenvalue_sum_2D',\n",
    " 'eigenvalue_ratio_2D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_features(voisin_num):\n",
    "    return pd.concat([vegetation_store[voisin_num],\n",
    "                      falaise_store[voisin_num],\n",
    "                      eboulis_store[voisin_num]], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_30 = concat_features(VOISIN_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1000 = concat_features(VOISIN_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1000.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_30 = features_30[FEATURE_NAMES].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_1000 = features_1000[FEATURE_NAMES].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can re-order the feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pd.Index(['beta', 'planarity', 'anisotropy', 'density_2D', 'density',\n",
    "       'verticality', 'eigenvalue_ratio_2D', 'eigenvalue_sum_2D',\n",
    "       'eigenvalue_sum', 'radius_2D', 'radius', 'std_dev', 'z_range', 'alpha',\n",
    "       'linearity', 'eigenentropy', 'omnivariance', 'scattering',\n",
    "       'curvature_change'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the following feature correlation matrix for 30 neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"white\", {'xtick.major.size': 12.0}):\n",
    "    fig, ax = plt.subplots(figsize=(16, 10))\n",
    "    sns.heatmap(rho_30.loc[cols, cols], square=True, cmap='RdBu_r',\n",
    "                center=0., linewidths=.5, annot=True, fmt=\".1f\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's plot the same information for 1000 neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"white\", {'xtick.major.size': 12.0}):\n",
    "    fig, ax = plt.subplots(figsize=(16, 10))\n",
    "    sns.heatmap(rho_1000.loc[cols, cols], square=True, cmap='RdBu_r',\n",
    "                center=0., linewidths=.5, annot=True, fmt=\".1f\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a PCA on geometric features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run this additional analysis, we need a few more dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geo3dfeatures.tools.kmean import load_features\n",
    "from geo3dfeatures.features import max_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first attempt to remove colinearities between the features in a generalisable way, we can apply Principle Component Analysis to the point cloud features for the whole scene, and for a small set of neighborhood sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_store = vegetation_store = pd.HDFStore(FEATURE_PATH / \"features.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENE_NEIGHBORHOODS = [50, 200, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = load_features(Path(\"..\", \"..\", DATAFOLDER), \"Pombourg\", SCENE_NEIGHBORHOODS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider a standardized version of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_features = StandardScaler().fit_transform(features.drop(columns=[\"x\", \"y\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run a PCA with 10 components, by assuming that the whole information can be summarized in less dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PCA(10).fit(norm_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As depicted by the following plot, the first component explain a large part of the model variance (~50%), whilst a projection on a 3 dimension space can explain 75% of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"white\", {'xtick.major.size': 12.0}):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.bar(range(model.n_components), model.explained_variance_)\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.set_ylim(0, 1)\n",
    "    ax2.plot(range(model.n_components), np.cumsum(model.explained_variance_ratio_), \"r\")\n",
    "    ax2.hlines(y=np.linspace(0, 1, 11), xmin=0, xmax=10, color='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enhance the insight on the state of features, we can plot all of them in a big heatmap..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_components = pd.DataFrame(model.components_.T, index=features.drop(columns=[\"x\", \"y\"]).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"white\", {'xtick.major.size': 12.0}):\n",
    "    fig, ax = plt.subplots(figsize=(10, 20))\n",
    "    sns.heatmap(pca_components, cmap='RdBu_r', fmt=\".2f\", ax=ax, center=0., linewidths=0.5, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a summary, we can see that the first component mixes a large part of the features, and the different neighborhood sizes do not really introduce variability. The second component brings a different information, based on verticality coefficients and 2D eigenvalue ratios. The third component is a slight variation of the first one. The fifth component is noticeable as it contains information about the color (with no particular distinction between RGB channels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** **TDLR Interpretation through PCA can bring further insights on data, and confirm the information provided by correlation matrix. However a raw use of PCA components as explicative variables in a (un)supervised learning algorithm does not seem relevant.** **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
